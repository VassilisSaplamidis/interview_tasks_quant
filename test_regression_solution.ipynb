{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Test for Canditates (2024) - Regression\n",
    "\n",
    "## Objective\n",
    "\n",
    "Make a predictive model for electricity consumption\n",
    "\n",
    "## Task\n",
    "\n",
    "An energy supplier provides electricity to it's customers in the Canton of Zurich. The customers are mainly businesses, offices and small industries. In order to buy the energy in the wholesale electricity market at the day before the delivery, the supplier needs to predict the total consumption of it's customers. \n",
    "\n",
    "The prediction takes place in the morning of every day and the next day's consumption needs to be forecasted.\n",
    "For example on **17.09.2023 08:00** we need to forecast the consumption from **18.09.2023 00:00 - 19.09.2023 00:00**\n",
    "\n",
    "The data available at the moment the prediction takes place are:\n",
    "- the weather forecasts for the next day (you can assume the forecast is perfect for this excersise)\n",
    "- the consumption of these customers up until the midnight of this day (eg. on **17.09.2023 08:00** the consumption up until **17.09.2023 00:00** is already known)\n",
    "\n",
    "## Dataset\n",
    "\n",
    "A dataset with the following columns:\n",
    "- `datetime_utc_from`: Datetime in UTC (the beginning of the hour)\n",
    "- `consumption_MWh`: The total electricity consumption of the energy supplier's customers (MWh)\n",
    "- `temperature_celsius`: Average temperature in the Canton of Zurich (Â°C)\n",
    "- `global_radiation_J`: Average solar radiation in the Canton of Zurich (J)\n",
    "\n",
    "## Binder link\n",
    "\n",
    "https://mybinder.org/v2/gh/VassilisSaplamidis/interview_tasks_quant/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Load neccesary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Feature engineering\n",
    "\n",
    "### What would be good features to use for this prediction?\n",
    "- Does temperature affect the electricity consumption patterns?\n",
    "- Does the amount of sun affect the electricity consumption patterns?\n",
    "- The customers are mainly industries and offices. Is there some expectation about their consumption pattern over different days/times of year?\n",
    "- Can you think of other features that might correlate with the electricity consumption of any given day?\n",
    "\n",
    "You should create these features now to use them in the model afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the dataset and set the index to datetime\n",
    "\n",
    "The dataset is loaded here. Pay attention that the index is UTC time.\n",
    "We also created a second datetime column that is in the local time zone of the customers, in case you find it useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('data_raw_regression.csv', delimiter=',')\n",
    "data.set_index('datetime_utc_from', inplace=True)\n",
    "data.index = pd.to_datetime(data.index, utc=True)\n",
    "data['datetime_local_from'] = data.index.tz_convert('Europe/Zurich')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create categorical features from the dates (DELETE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the day-of-week, month columns\n",
    "data['day_of_week'] = data['datetime_local_from'].dt.day_of_week\n",
    "data['hour'] = data['datetime_local_from'].dt.hour\n",
    "data['month'] = data['datetime_local_from'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create features from the 48h and 7d lagged target (DELETE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['consumption_48h_ago'] = data['consumption_MWh'].shift(48)\n",
    "data['consumption_7d_ago'] = data['consumption_MWh'].shift(24*7)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create the dataset for the model\n",
    "\n",
    "### 1. Split the data into features (X) and target (y)\n",
    "\n",
    "The target column should be `y = data['consumption_MWh']`\n",
    "\n",
    "### 2. One-hot encode categorical features (example code)\n",
    "```\n",
    "categorical_features = ['feature4', 'feature6']\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_cats = encoder.fit_transform(X[categorical_features])\n",
    "encoded_df = pd.DataFrame(encoded_cats, index=X.index, columns=encoder.get_feature_names_out(categorical_features))\n",
    "X_encoded = pd.concat([X.drop(columns=categorical_features), encoded_df], axis=1)\n",
    "```\n",
    "\n",
    "### 3. Any other preprocessing you want "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Separate features (X) and target (y) (DELETE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "feature_cols = ['temperature_celsius', 'global_radiation_J', 'consumption_48h_ago', 'consumption_7d_ago', 'day_of_week', 'hour', 'month']\n",
    "X = data[feature_cols]\n",
    "y = data['consumption_MWh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. One-hot encode categorical features (DELETE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical features\n",
    "categorical_features = ['day_of_week', 'hour', 'month']\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_cats = encoder.fit_transform(X[categorical_features])\n",
    "\n",
    "# Create a dataframe for the encoded features\n",
    "encoded_df = pd.DataFrame(encoded_cats, index=X.index, columns=encoder.get_feature_names_out(categorical_features))\n",
    "X_encoded = pd.concat([X.drop(columns=categorical_features), encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare data for the model (DELETE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the date range for the test set\n",
    "test_start_date = '2023-10-01'\n",
    "test_end_date = '2023-10-30'\n",
    "\n",
    "test_indices = (data.index >= test_start_date) & (data.index <= test_end_date)\n",
    "train_indices = ~test_indices\n",
    "\n",
    "X_train = X_encoded[train_indices]\n",
    "X_test = X_encoded[test_indices]\n",
    "y_train = y[train_indices]\n",
    "y_test = y[test_indices]\n",
    "\n",
    "if (X_train.isnull().sum().sum() > 0) or (y_train.isnull().sum() > 0):\n",
    "    raise ValueError(\"Training data contains NaN values. Please clean the data before proceeding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Building\n",
    "\n",
    "Remember that the goal is to have a good predictive model that is robust and can be used to predict unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model (DELETE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column transformer with scaling and one-hot encoding\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['temperature_celsius', 'global_radiation_J', 'consumption_48h_ago', 'consumption_7d_ago']),\n",
    "    ])\n",
    "\n",
    "# Define the Ridge regression pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'ridge__alpha': np.logspace(-6, 6, 11),\n",
    "    'ridge__fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_absolute_percentage_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "try:\n",
    "    grid_search.fit(X_train, y_train)\n",
    "except Exception as e:\n",
    "    print(f\"Grid search failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evaluation\n",
    "\n",
    "- Can you estimate how good your model performed? \n",
    "- Do you think it can be used to predict unseen data? Why? Why not?\n",
    "- What improvements would you do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation (DELETE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {-grid_search.best_score_}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_score = grid_search.score(X_test, y_test)\n",
    "print(f\"Test set score: {-test_score}\")\n",
    "\n",
    "# Get the predictions for the test set\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Plot the actual values vs. the predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test.index, y_test, label='Actual')\n",
    "plt.plot(y_test.index, y_pred, label='Predicted')\n",
    "\n",
    "plt.xlabel('Date Time')\n",
    "plt.ylabel('Consumption (MWh)')\n",
    "plt.title('Actual vs. Predicted Consumption (MWh)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
